Санкт-Петербургский политехнический университет Петра Великого Институт компьютерных наук и технологий
Высшая школа программной инженерии


















Лабораторная работа №1

 «Методы классификации»
по дисциплине «Машинное обучение»

Вариант №14














Выполнил студент 
гр. 3530904/90105	:		                                                                           Пятышев К. А.

Руководитель:	Селин И. А.





Санкт-Петербург 
2022
 
Ход работы

Задание 1.
I.	Классификация игры крестика-нолики(файл tic_tac_toe.txt)
 
Отношение обучающей выборки к тестовой почти не влияет на погрешность из-за небольшого количества данных.



II.	Классификация о спаме e-mail сообщений (файл spam.csv)
 
Погрешность остаётся практически неизменной.






Задание 2.
I.	Генерация 100 точек с признаками(Вариант 14)
II.	Построить Байесовский классификатор 
Вариант	Матем. ожид. X1 (класс -1)	Матем. ожид. X2 (класс -1)	Дисперсия (класс -1)	Матем. ожид. X1 (класс 1)	Матем. ожид. X2 (класс 1)	Дисперсия (класс 1)	Количество элементов (класс -1)	Количество элементов (класс 1)
14	10	23	3	7	10	2	50	50

График, сгенерированных точки
 
Зеленый точки – с математическими ожиданиями 10 и 23
Синие точки – с математическими ожиданиями 7 и 10
Dataset включает в себя 100 наборов данных (82 на обучение и 18 на тестирование).
	Результаты:
Точность: 1.0 (100%)
9	0
0	9
Матрица:  
		


 
Полученные графики
 
 

Поскольку классы находятся далеко друг от друга , можем сделать вывод о том , что  точность получается 100%.
 
Задание 3.
I.	Классификация на основе метода ближайших соседей(файл glass.csv)
 
Метрики расстояния:

Минковского	Чебышева	Евклида	Манхэттенская
0.39534883720930236	0.41860465116279066	0.39534883720930236	0.32558139534883723

Экземпляр с характеристиками:
RI =1.516 Na =11.7 Mg =1.01 Al =1.19 Si =72.59 K=0.43 Ca =11.44 Ba =0.02 Fe =0.1 
принадлежит к пятому классу:
	1	2	3	4	5	6	7
Количество	0	12	0	0	16	0	0

 
Задание 4.
I.	Классификаторы на основе метода опорных векторов(файлы svmdataN.txt и svmdataNtest.txt)

A.	Линейное ядро
График зависимости:
 

Матрица ошибок: 
	Тестовая	Обучающая
Тестовая	20	0
Обучающая	0	20

В классификаторе присутствует 3 опорных вектора. Точность составила 100% процентов

B.	На тестовой выборке удалось достигнуть 100% точности уже при С = 1. Для получения такого же результата для обучающей выборки пришлось увеличить параметр С до 500, но при этом изменении страдает точность результата на тестовой выборке, исходя из этого лучше брать параметр меньше 500.
 
 
На  обучающей выборке у нас получаются хорошие результаты. При С > 180 нейросеть переобучается.


C.	Данные невозможно разделить линейной функцией. Достаточно хорошо справляются полиномиальные методы с чётными степенями и гауссово ядро.
        

D.	В этом случае ядро Гаусса показывает лучшую эффективность, однако и полиномиальные ядра первой, второй и третьей степеней также показывают неплохой результат.
       

E.	Достигнуть явного переобучения не удалось. При увеличении параметра С от 1000 нет явных изменений.
        
  
  
 


Теперь будем менять параметр гамма.
I.	Гамма = 50
       



II.	Гамма = 150
      
Можно заметить, что У гауссова ядра в середине синей зоны начинают появляться красные области.

III.	Гамма = 300
    
Здесь наблюдается явное переобучение.



Задание 5.
I.	Построить классификаторы для различных данных на основе деревьев решений 
a)	Набор данных Glass (файл glass.csv)
 Точность: 0.6976744186046512
 

b)	Набор данных spam7(файл spam7.csv)
1) Стандартное значение:

 Глубина: 12
Точность: 0.8566775244299675

  Глубина: 10
Точность: 0.8555917480998915
  
Глубина: 8                                                                                                      Глубина: 6

Точность: 0.8729641693811075                                    Точность:0.8697068403908795

  
Глубина: 4
Точность: 0.8599348534201955

По сравнению с глубиной равной восьми точность ухудшилась. Наивысшая точность была достигнута при глубине равной восьми.

c)	Набор данных bank (файл bank_scoring_train.csv)

Построим несколько вариантов систем на основе различных классификаторов. 

Матрицы ошибок:

Decision Tree Classifier: 0.95181474244377
21788	619
540	1106







K Neighbors Classifier: 0.9536856109425019
21952	455
659	987





SVC: 0.93152621294641
22406	1
1646	0




Decision Tree Classifier оказалось лучше других, потому что именно в данном случае мы получили наибольший показатель невыдачи отрицательным заемщикам при высоком показателе выдачи положительным клиентам. Также можно заметить, что показатели неудачных выдач в сумме меньше, чем в остальных случаях.
 

Код на языке Python:
1.	KNN_classifier.py

import matplotlib.pyplot as plt import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split from sklearn.neighbors import KNeighborsClassifier

def get_data(file_name):
f = pd.read_csv(file_name) state = f[list(f)[1:-1]]
state_bin = pd.get_dummies(state) x = np.array(state_bin)

y = f[list(f)[-1]]
le = preprocessing.LabelEncoder() y = le.fit_transform(y)

return x, y


def train(x, y, n_neighbors, dist_name):
neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=dist_name) neigh.fit(x, y)

return neigh
 

def evaluate_predictions(test_y_data, predictions):
bac = balanced_accuracy_score(test_y_data, predictions)

print(f"Несбалансированная метрика = {accuracy_score(test_y_data, predictions)}")
print(f"Сбалансированная метрика= {balanced_accuracy_score(test_y_data, predictions)}")
print("\nМатрица ошибок:") print(confusion_matrix(test_y_data, predictions)) print(classification_report(test_y_data, predictions)) return bac


def plot(n_neighbors_arr, accuracy_score_arr, x_axis_name): plt.xlabel(x_axis_name)
plt.ylabel("Точность")

plt.bar(n_neighbors_arr, accuracy_score_arr) plt.show()


def glass_example(): n_neighbors_arr = []
n_neighbors_accuracy_score_arr = []

x, y = get_data("glass.csv")

train_x_data = [] train_y_data = [] test_x_data = [] test_y_data = []

train_x_data, test_x_data, train_y_data, test_y_data = train_test_split(x, y, test_size=0.33)

# a
dist_name = 'minkowski'
for n_neighbors in range(1, 10): print(f'Количество соседей = {n_neighbors}') n_neighbors_arr.append(n_neighbors)
neigh = train(train_x_data, train_y_data, n_neighbors, dist_name) predictions = neigh.predict(test_x_data)

n_neighbors_accuracy_score_arr.append(evaluate_predictions(test_y_data, predictions))

# b
n_neighbors = 3
dist_names = ('euclidean', 'manhattan', 'chebyshev', 'minkowski') dist_names_accuracy_score_arr = []

for dist_name in dist_names:
neigh = train(train_x_data, train_y_data, n_neighbors, dist_name) predictions = neigh.predict(test_x_data)

dist_names_accuracy_score_arr.append(evaluate_predictions(test_y_data, predictions))

# c
n_neighbors = 3 dist_name = 'minkowski'
neigh = train(train_x_data, train_y_data, n_neighbors, dist_name)
 
predictions = neigh.predict([[1.516, 11.7, 1.01, 1.19, 72.59, 0.43,
11.44, 0.02, 0.1]])

print(
'Типы стекла со свойствами: RI =1.516 Na =11.7 Mg =1.01 Al =1.19 Si
=72.59 K=0.43 Ca =11.44 Ba =0.02 Fe =0.1')
print('Тип стекла:', predictions[0])

plot(dist_names, dist_names_accuracy_score_arr, 'Метрика расстояния') plot(n_neighbors_arr, n_neighbors_accuracy_score_arr, 'Количество
соседей')

glass_example()



2.	bayes_classifier.py


import matplotlib.pyplot as plt import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, plot_precision_recall_curve from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB


def get_data(file_name):
f = pd.read_csv(file_name) state = f[list(f)[:-1]]
state_bin = pd.get_dummies(state) x = np.array(state_bin)

y = f[list(f)[-1]]
le = preprocessing.LabelEncoder() y = le.fit_transform(y)

return x, y

def train(x, y, test_data_coef): train_x_data = [] train_y_data = [] test_x_data = []
test_y_data = []

train_x_data, test_x_data, train_y_data, test_y_data = train_test_split(x, y, test_size=test_data_coef)

model = GaussianNB() model.fit(train_x_data, train_y_data) predictions = model.predict(test_x_data)

return test_y_data, predictions


def evaluate_predictions(test_y_data, predictions):
bac = balanced_accuracy_score(test_y_data, predictions)

 
print(f"Unbalanced_accuracy = {accuracy_score(test_y_data, predictions)}")
print(f"Balanced_accuracy = {balanced_accuracy_score(test_y_data, predictions)}")
print("\nConfusion matrix:") print(confusion_matrix(test_y_data, predictions)) print(classification_report(test_y_data, predictions)) return bac


def plot(test_data_coef_arr, accuracy_score_arr): plt.xlabel("Коэффициент тестовых данных") plt.ylabel("Точность")

plt.plot(test_data_coef_arr, accuracy_score_arr, c='green') plt.show()


def tic_tac_toe_example(): test_data_coef_arr = [] accuracy_score_arr = []

x, y = get_data("tic_tac_toe.txt")

for test_data_coef in np.arange(0.05, 0.95, 0.01): test_data_coef_arr.append(test_data_coef)
test_y_data, predictions = train(x, y, test_data_coef) accuracy_score_arr.append(evaluate_predictions(test_y_data,
predictions))

plot(test_data_coef_arr, accuracy_score_arr) plt.show()


def spam_example(): test_data_coef_arr = [] accuracy_score_arr = []

x, y = get_data("spam.csv")

for test_data_coef in np.arange(0.05, 0.95, 0.01): test_data_coef_arr.append(test_data_coef)
test_y_data, predictions = train(x, y, test_data_coef) accuracy_score_arr.append(evaluate_predictions(test_y_data,
predictions))

plot(test_data_coef_arr, accuracy_score_arr)


def roc_curve_plot(test_y_data, y_score): plt.figure(figsize=(6, 5))
fpr, tpr, thresholds = roc_curve(test_y_data, y_score[:, 1], pos_label=1) lw = 2
plt.plot(fpr, tpr, lw=lw, label='ROC-кривая') plt.plot([0, 1], [0, 1])
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Ложная положительная оценка') plt.ylabel('Истинная положительная оценка') plt.title('ROC кривая')


def dots_example():
 
test_data_coef_arr = [] accuracy_score_arr = []

x = []
y = []
x0_arr_class_1 = [] x1_arr_class_1 = [] x0_arr_class_2 = [] x1_arr_class_2 = []

#for i in range(80):
for i in range(50):
#x0 = np.random.normal(13, 2) x0 = np.random.normal(10, 3) #x1 = np.random.normal(20, 2) x1 = np.random.normal(23, 3) x0_arr_class_1.append(x0) x1_arr_class_1.append(x1) x.append([x0, x1])
y.append(-1)

#for i in range(20):
for i in range(50):
#x0 = np.random.normal(20, 2) x0 = np.random.normal(7, 2) #x1 = np.random.normal(4, 2) x1 = np.random.normal(10, 2) x0_arr_class_2.append(x0) x1_arr_class_2.append(x1) x.append([x0, x1]) y.append(1)

plt.xlabel("Значение x0") plt.ylabel("Значение x1")

plt.plot(x0_arr_class_1, x1_arr_class_1, 'o', c = 'r') plt.plot(x0_arr_class_2, x1_arr_class_2, 'o', c = 'b') plt.show()

le = preprocessing.LabelEncoder() y = le.fit_transform(y)

test_data_coef = 0.33

train_x_data = [] train_y_data = [] test_x_data = [] test_y_data = []

train_x_data, test_x_data, train_y_data, test_y_data = train_test_split(x, y, test_size=test_data_coef)

model = GaussianNB()
y_score = model.fit(train_x_data, train_y_data).predict_proba(test_x_data)
predictions = model.predict(test_x_data)

evaluate_predictions(test_y_data, predictions)

roc_curve_plot(test_y_data, y_score)
disp = plot_precision_recall_curve(model, test_x_data, test_y_data) disp.ax_.set_title('PR кривая: '
'AP={0:0.2f}'.format(0.01))

plt.show() 
dots_exampl()
 



3.	decision_tree.py


import os
os.environ["PATH"] += os.pathsep + 'D:/Program Files (x86)/Graphviz2.38/bin/' import graphviz
import numpy as np import pandas as pd
from sklearn import preprocessing from sklearn import tree
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split


def get_data_spam7(file_name): f = pd.read_csv(file_name) state = f[list(f)[:-1]]
state_bin = pd.get_dummies(state) x = np.array(state_bin)

y = f[list(f)[-1]]
le = preprocessing.LabelEncoder() y = le.fit_transform(y)
return x, y


def get_data_glass(file_name): f = pd.read_csv(file_name) state = f[list(f)[1:-1]]
state_bin = pd.get_dummies(state) x = np.array(state_bin)

y = f[list(f)[-1]]
le = preprocessing.LabelEncoder() y = le.fit_transform(y)
return x, y


def evaluate_predictions(test_y_data, predictions):
bac = balanced_accuracy_score(test_y_data, predictions)

print(f"Несбалансированная метрика = {accuracy_score(test_y_data, predictions)}")
print(f"Сбалансированная метрика = {balanced_accuracy_score(test_y_data, predictions)}")
print("\nМатрица ошибок:") print(confusion_matrix(test_y_data, predictions)) print(classification_report(test_y_data, predictions)) return bac


def train(x, y, feature_names, target_names, res_graph_name): train_x_data = []
train_y_data = []
 
test_x_data = [] test_y_data = []

train_x_data, test_x_data, train_y_data, test_y_data = train_test_split(x, y, test_size=0.33)

clf = tree.DecisionTreeClassifier(criterion= 'gini', max_depth = None, min_samples_leaf = 1)
clf = clf.fit(train_x_data, train_y_data) print(clf.feature_importances_)
dot_data = tree.export_graphviz(clf, out_file=None,
feature_names=feature_names, class_names=target_names, special_characters=True)

graph = graphviz.Source(dot_data) graph.render(res_graph_name)

predictions = clf.predict(test_x_data) evaluate_predictions(test_y_data, predictions)


def glass_example_tree():
x, y = get_data_glass("glass.csv") f = pd.read_csv("glass.csv")
feature_names = list(f.columns[1:-1])
target_names = [str(elem) for elem in np.unique(f[list(f)[-1]])] train(x, y, feature_names, target_names, 'glass_graph')


def spam7_example_tree():
x, y = get_data_spam7("spam7.csv") f = pd.read_csv("spam7.csv")
feature_names = list(f.columns[0:-1]) print(feature_names)
target_names = [str(elem) for elem in np.unique(f[list(f)[-1]])] train(x, y, feature_names, target_names, 'spam7_graph')
spam7_example_tree()

4.	bank_scoring_example.py

import pandas as pd
from sklearn import preprocessing from sklearn import tree
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score from sklearn.metrics import classification_report from sklearn.metrics import confusion_matrix
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier


def get_data(file_name):
f = pd.read_csv(file_name, sep='\t') x = f[list(f)[1:]]

y = f[list(f)[0]]
le = preprocessing.LabelEncoder() y = le.fit_transform(y)

return x, y
 

def evaluate_predictions(test_y_data, predictions):
bac = balanced_accuracy_score(test_y_data, predictions)

print(f"Несбалансированная точность = {accuracy_score(test_y_data, predictions)}")
print(f"Сбалансированная точность = {balanced_accuracy_score(test_y_data, predictions)}")
print("\nConfusion matrix:") print(confusion_matrix(test_y_data, predictions)) print(classification_report(test_y_data, predictions))


def bank_scoring_example():
X, y = get_data("bank_scoring_train.csv")
X_test, y_test = get_data('bank_scoring_test.csv')

print("GaussianNB") model = GaussianNB() model.fit(X, y)
predictions = model.predict(X_test) evaluate_predictions(y_test, predictions)

print("kNN") n_neighbors = 1
neigh = KNeighborsClassifier(n_neighbors=n_neighbors) neigh.fit(X, y)
predictions = neigh.predict(X_test) evaluate_predictions(y_test, predictions)

print("Decision tree")
clf = tree.DecisionTreeClassifier() clf = clf.fit(X, y)
predictions = clf.predict(X_test) evaluate_predictions(y_test, predictions)

bank_scoring_example()
 
Количетсво символов: 15410
Количетсво символов без пробелов: 13873
